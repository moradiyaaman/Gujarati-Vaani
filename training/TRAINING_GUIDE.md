# Gujarati Vaani - Fine-Tuning Pipeline

## üéì Educational Guide: How Training Works

This document explains the complete fine-tuning pipeline for the Gujarati Vaani TTS system.

---

## üìê The GitHub-Azure Cloud Loop

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    THE TRAINING ARCHITECTURE                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                      ‚îÇ
‚îÇ   ‚îÇ  YOUR LAPTOP     ‚îÇ                                                      ‚îÇ
‚îÇ   ‚îÇ  (Development)   ‚îÇ                                                      ‚îÇ
‚îÇ   ‚îÇ                  ‚îÇ                                                      ‚îÇ
‚îÇ   ‚îÇ  - Edit code     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄpush‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                     ‚îÇ
‚îÇ   ‚îÇ  - Test locally  ‚îÇ                ‚îÇ                                     ‚îÇ
‚îÇ   ‚îÇ  - Review results‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄpull‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                                     ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ                                     ‚îÇ
‚îÇ                                       ‚ñº                                     ‚îÇ
‚îÇ                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                           ‚îÇ      GITHUB          ‚îÇ                          ‚îÇ
‚îÇ                           ‚îÇ  (Source Control)    ‚îÇ                          ‚îÇ
‚îÇ                           ‚îÇ                      ‚îÇ                          ‚îÇ
‚îÇ                           ‚îÇ  - train.py          ‚îÇ                          ‚îÇ
‚îÇ                           ‚îÇ  - requirements.txt  ‚îÇ                          ‚îÇ
‚îÇ                           ‚îÇ  - utils/            ‚îÇ                          ‚îÇ
‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                      ‚îÇ                                      ‚îÇ
‚îÇ                                      ‚îÇ git clone                            ‚îÇ
‚îÇ                                      ‚ñº                                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ   ‚îÇ                    AZURE ML COMPUTE INSTANCE                          ‚îÇ ‚îÇ
‚îÇ   ‚îÇ                    Standard_NC6 (Tesla T4 GPU)                        ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ                                                                 ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   /home/azureuser/gujarati-vaani/                              ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ training/                                                 ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.py  ‚óÑ‚îÄ‚îÄ‚îÄ Runs on GPU                           ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ utils/                                                    ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_utils.py  ‚óÑ‚îÄ‚îÄ‚îÄ Text preprocessing               ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ model_weights/                                            ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ finetuned/  ‚óÑ‚îÄ‚îÄ‚îÄ OUTPUT (trained model)              ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ samples/                                                  ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation_*.wav  ‚óÑ‚îÄ‚îÄ‚îÄ Hourly samples                ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ logs/                                                     ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ tensorboard/  ‚óÑ‚îÄ‚îÄ‚îÄ Training metrics                  ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îÇ                                                                 ‚îÇ ‚îÇ ‚îÇ
‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                      ‚îÇ                                      ‚îÇ
‚îÇ                                      ‚îÇ reads from                           ‚îÇ
‚îÇ                                      ‚ñº                                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ   ‚îÇ                    AZURE BLOB STORAGE                                 ‚îÇ ‚îÇ
‚îÇ   ‚îÇ                    (Mounted as /data)                                 ‚îÇ ‚îÇ
‚îÇ   ‚îÇ                                                                       ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   /data/indic_tts/guj/                                               ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/                                                          ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio/                                                      ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_0001.wav  (16kHz mono)                          ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_0002.wav                                         ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (1000s of files)                                   ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.csv                                                ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ       # Format: filename|gujarati_text|speaker_id                ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ       sample_0001.wav|‡™®‡™Æ‡™∏‡´ç‡™§‡´á, ‡™Ü ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä ‡™õ‡´á.|speaker_1           ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ       sample_0002.wav|‡™Ü‡™ú‡´á ‡™π‡™µ‡™æ‡™Æ‡™æ‡™® ‡™∏‡™æ‡™∞‡´Å‡™Ç ‡™õ‡´á.|speaker_1            ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ                                                                   ‚îÇ ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ valid/                                                          ‚îÇ ‚îÇ
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ audio/                                                      ‚îÇ ‚îÇ
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metadata.csv                                                ‚îÇ ‚îÇ
‚îÇ   ‚îÇ                                                                       ‚îÇ ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üî¨ Technical Deep-Dive

### Why 16kHz Sample Rate?

The Meta MMS VITS model was trained on **16kHz audio**. This is embedded in the model's architecture:

```python
# The HiFi-GAN vocoder has these fixed parameters:
upsample_rates = [8, 8, 2, 2]  # Total: 8 √ó 8 √ó 2 √ó 2 = 256
hop_length = 256
# Output: input_length √ó 256 samples

# For 1 second of audio:
# 16000 samples √∑ 256 = 62.5 mel frames per second
```

If we used 22kHz or 44kHz audio:
- The vocoder would produce audio at the wrong speed
- Retraining the vocoder requires **100+ hours of GPU time**
- The mel-spectrogram bins wouldn't align

**Solution**: Always resample input audio to 16kHz before training.

---

### Why Freeze the Text Encoder?

The VITS model has two main components:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         VITS MODEL                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ              TEXT ENCODER (Frozen ‚ùÑÔ∏è)                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   Input: "‡™®‡™Æ‡™∏‡´ç‡™§‡´á" (Gujarati Unicode)                     ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚îÇ                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚ñº                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ Embedding Layer                                 ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Maps each Gujarati character to 192-dim vector‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Vocabulary: ~150 Gujarati characters          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚îÇ                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚ñº                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ Transformer Layers (6 layers)                   ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Self-attention for context                    ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Feed-forward networks                         ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Learns: "How to pronounce Gujarati"           ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚îÇ                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚ñº                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   Output: Phonetic representation (hidden states)       ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   Parameters: ~30 million (FROZEN)                      ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   Why freeze? It already knows Gujarati perfectly!      ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                         ‚îÇ                                      ‚îÇ
‚îÇ                         ‚ñº                                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ              DECODER + VOCODER (Trainable üî•)            ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ Duration Predictor                              ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Learns: How long each phoneme lasts           ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Adapts to new speaker's pace                  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚îÇ                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚ñº                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ Flow-based Decoder                              ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Learns: Speaker's voice characteristics       ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Pitch patterns, prosody, timbre               ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚îÇ                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚ñº                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ HiFi-GAN Vocoder                                ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Converts mel-spectrogram to audio waveform    ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îÇ ‚Ä¢ Learns: Speaker's acoustic signature          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚îÇ                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                    ‚ñº                                    ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   Output: Audio waveform (16kHz)                        ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   Parameters: ~50 million (TRAINABLE)                   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ   What it learns: "How to sound like this speaker"      ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benefits of Freezing:**
1. **VRAM Savings**: 40% less memory needed (no gradients for encoder)
2. **Prevent Forgetting**: Encoder learned Gujarati phonetics from 1000+ hours of data
3. **Faster Training**: 2x speed improvement
4. **Better Results**: Focus learning on what matters (voice quality)

---

### Gradient Accumulation Explained

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   WITHOUT GRADIENT ACCUMULATION                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   Batch Size = 16 ‚Üí CRASH! Out of Memory (T4 has only 16GB)    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   Memory breakdown:                                             ‚îÇ
‚îÇ   ‚Ä¢ Model weights: ~400MB                                       ‚îÇ
‚îÇ   ‚Ä¢ Optimizer states: ~800MB (AdamW uses 2x model size)        ‚îÇ
‚îÇ   ‚Ä¢ Gradients: ~400MB                                           ‚îÇ
‚îÇ   ‚Ä¢ Activations: ~8GB for batch of 16                          ‚îÇ
‚îÇ   ‚Ä¢ Audio data: ~4GB                                            ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                             ‚îÇ
‚îÇ   Total: ~13.6GB + overhead = üí• OOM                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   WITH GRADIENT ACCUMULATION                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   Batch Size = 4, Accumulation Steps = 4                        ‚îÇ
‚îÇ   Effective Batch = 4 √ó 4 = 16                                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   Step 1: Forward(batch_1) ‚Üí Backward ‚Üí Accumulate gradients   ‚îÇ
‚îÇ   Step 2: Forward(batch_2) ‚Üí Backward ‚Üí Accumulate gradients   ‚îÇ
‚îÇ   Step 3: Forward(batch_3) ‚Üí Backward ‚Üí Accumulate gradients   ‚îÇ
‚îÇ   Step 4: Forward(batch_4) ‚Üí Backward ‚Üí Accumulate gradients   ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ Now: optimizer.step() ‚Üê Update weights            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   Memory per step: ~5GB ‚úì Fits in T4!                          ‚îÇ
‚îÇ   Mathematical result: Same as batch=16                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Mixed Precision (FP16) Training

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      FP32 vs FP16                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   FP32 (32-bit floating point):                                ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ   ‚îÇ Sign ‚îÇ    Exponent (8 bits)    ‚îÇ   Mantissa (23 bits)   ‚îÇ  ‚îÇ
‚îÇ   ‚îÇ  1   ‚îÇ  0 1 0 0 0 0 0 0        ‚îÇ  1 0 0 1 0 0 0 ...     ‚îÇ  ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ   ‚Ä¢ Range: ¬±3.4 √ó 10^38                                        ‚îÇ
‚îÇ   ‚Ä¢ Precision: 7 decimal digits                                 ‚îÇ
‚îÇ   ‚Ä¢ Memory: 4 bytes per number                                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   FP16 (16-bit floating point):                                ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ
‚îÇ   ‚îÇ Sign ‚îÇ  Exp (5)  ‚îÇ  Mantissa (10)   ‚îÇ                      ‚îÇ
‚îÇ   ‚îÇ  1   ‚îÇ  1 0 0 0 0‚îÇ  1 0 0 1 0 0 ... ‚îÇ                      ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ
‚îÇ   ‚Ä¢ Range: ¬±65,504                                              ‚îÇ
‚îÇ   ‚Ä¢ Precision: 3 decimal digits                                 ‚îÇ
‚îÇ   ‚Ä¢ Memory: 2 bytes per number (50% savings!)                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   Tesla T4 Tensor Cores:                                        ‚îÇ
‚îÇ   ‚Ä¢ FP32: 8.1 TFLOPS                                           ‚îÇ
‚îÇ   ‚Ä¢ FP16: 65 TFLOPS (8x faster!)                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ   torch.cuda.amp automatically:                                 ‚îÇ
‚îÇ   ‚Ä¢ Uses FP16 for forward/backward (fast)                      ‚îÇ
‚îÇ   ‚Ä¢ Keeps FP32 for optimizer (stable)                          ‚îÇ
‚îÇ   ‚Ä¢ Handles loss scaling to prevent underflow                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Azure ML Monitoring

### TensorBoard Setup

```bash
# On Azure Compute Instance:
tensorboard --logdir ./logs --port 6006 --bind_all

# Then in Azure ML Studio:
# Go to Compute > Your Instance > Applications > Add > Port 6006
```

### Key Metrics to Watch

| Metric | Good Range | What It Means |
|--------|------------|---------------|
| `Loss/total` | 0.1 - 1.0 | Overall training progress |
| `Loss/reconstruction` | 0.05 - 0.5 | Audio quality (lower = better) |
| `Loss/kl_divergence` | 0.01 - 0.1 | Speech flow naturalness |
| `Training/learning_rate` | Decreasing | Should follow warmup schedule |
| `Training/step_time` | 1-3 seconds | GPU utilization |

### Warning Signs

| Problem | Symptom | Solution |
|---------|---------|----------|
| Overfitting | Valid loss increases while train decreases | Reduce epochs, add dropout |
| Underfitting | Both losses plateau high | Increase learning rate or epochs |
| Gradient explosion | Loss becomes NaN | Reduce learning rate, check data |
| OOM Errors | CUDA out of memory | Reduce batch size |

---

## üöÄ Running Training

### Quick Start

```bash
# 1. Clone repository on Azure
git clone https://github.com/your-repo/gujarati-vaani.git
cd gujarati-vaani

# 2. Run setup
chmod +x training/azure_setup.sh
./training/azure_setup.sh

# 3. Start training
python training/train.py \
    --data-dir /data/indic_tts/guj \
    --output-dir ./model_weights/finetuned \
    --epochs 50 \
    --batch-size 4
```

### Expected Training Time

| Dataset Size | Epochs | Time (T4 GPU) |
|--------------|--------|---------------|
| 10 hours audio | 50 | ~8 hours |
| 50 hours audio | 50 | ~40 hours |
| 100 hours audio | 30 | ~48 hours |

---

## üì¶ Using the Trained Model

After training completes, copy the model back to your local project:

```bash
# On your local machine:
scp -r azureuser@<compute-ip>:~/gujarati-vaani/model_weights/finetuned ./model_weights/

# Or use Azure Storage:
az storage blob upload-batch \
    -d models/finetuned \
    -s ./model_weights/finetuned
```

Then update `utils/tts.py` to load the fine-tuned model:

```python
# In load_mms_guj():
_FINETUNED_MODEL_DIR = _MODEL_DIR / "finetuned" / "best"

if _FINETUNED_MODEL_DIR.exists():
    model = VitsModel.from_pretrained(str(_FINETUNED_MODEL_DIR))
    print("‚úÖ Loaded fine-tuned model!")
```

---

## üìù Troubleshooting

| Issue | Solution |
|-------|----------|
| "ModuleNotFoundError: utils.text_utils" | Run from project root, not training/ folder |
| "FileNotFoundError: metadata.csv" | Check data path, ensure dataset is mounted |
| "CUDA out of memory" | Reduce batch_size to 2 |
| "RuntimeError: NCCL error" | Single GPU only, not distributed |
| Poor audio quality | Train longer, check audio preprocessing |

---

*Created for Gujarati Vaani - SEM 6 SDP Project*
